[
    {
        "prompt_fl_1": {
            "doubao-pro-4k": "7",
            "qwen-turbo": "14",
            "ernie-3.5-128k": "**21**",
            "deepseek-chat": "14",
            "gpt-4o-mini": "39"
        },
        "prompt_fl_2": {
            "doubao-pro-4k": "10",
            "qwen-turbo": "32",
            "ernie-3.5-128k": "36",
            "deepseek-chat": "32",
            "gpt-4o-mini": "32"
        },
        "prompt_fl_3": {
            "qwen-turbo": "32",
            "deepseek-chat": "32",
            "ernie-3.5-128k": "**43**",
            "doubao-pro-4k": "32",
            "gpt-4o-mini": "32"
        },
        "prompt_fl_4": {
            "doubao-pro-4k": "if (charsetName == null) {",
            "qwen-turbo": "docData = Charset.forName(defaultCharset).decode(byteData).toString();",
            "ernie-3.5-128k": "docData = Charset.forName(defaultCharset).decode(byteData).toString();",
            "deepseek-chat": "```java\ndocData = Charset.forName(defaultCharset).decode(byteData).toString();\n```",
            "gpt-4o-mini": "byteData.rewind();"
        },
        "prompt_fl_5": {
            "qwen-turbo": "doc = parser.parseInput(docData, baseUri);",
            "doubao-pro-4k": "doc = parser.parseInput(docData, baseUri);",
            "ernie-3.5-128k": "docData = Charset.forName(defaultCharset).decode(byteData).toString();",
            "deepseek-chat": "docData = Charset.forName(defaultCharset).decode(byteData).toString();",
            "gpt-4o-mini": "doc = parser.parseInput(docData, baseUri);"
        },
        "prompt_fl_6": {
            "qwen-turbo": "doc = parser.parseInput(docData, baseUri);",
            "doubao-pro-4k": "assertEquals(\"One\", doc.head().text());",
            "deepseek-chat": "docData = Charset.forName(charsetName).decode(byteData).toString();",
            "ernie-3.5-128k": "`docData = Charset.forName(defaultCharset).decode(byteData).toString();`",
            "gpt-4o-mini": "doc = parser.parseInput(docData, baseUri);"
        },
        "prompt_apr_1": {
            "qwen-turbo": "Certainly! The bug you're referring to is likely related to how the `doc` object is being handled when the charset is determined from the `<meta>` tag. Specifically, the `doc` object should be re-parsed after determining the correct charset. Here's the corrected version of the method:\n\n```java\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(\"UTF-8\").decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(\"UTF-8\")) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null; // Reset doc to null to force re-parsing\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}\n```\n\nIn this corrected version, I've ensured that `doc` is reset to `null` before re-parsing if the charset is determined from the `<meta>` tag. This ensures that the document is correctly re-parsed with the detected charset.",
            "gpt-4o-mini": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null;\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}",
            "deepseek-chat": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null;\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n        if (docData.length() > 0 && docData.charAt(0) == '\\uFEFF') {\n            docData = docData.substring(1);\n        }\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}",
            "doubao-pro-4k": "\u4ee5\u4e0b\u662f\u4fee\u6b63\u540e\u7684\u4ee3\u7801\uff1a\n\n```java\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta!= null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\")? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset!= null && foundCharset.length()!= 0 &&!foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null;\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n\n        docData = docData.replaceFirst(\"\\uFEFF\", \"\"); // Bug fix here\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}\n```",
            "ernie-3.5-128k": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        String defaultCharset = \"UTF-8\"; // Ensure defaultCharset is defined\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null; // Reset doc to re-parse with correct charset\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n        \n        doc = parser.parseInput(docData, baseUri);\n        if (charsetName != null) {\n            doc.outputSettings().charset(charsetName);\n        } else {\n            doc.outputSettings().charset(\"UTF-8\"); // Default to UTF-8 if charsetName is null here\n        }\n    }\n    return doc;\n}"
        },
        "prompt_apr_2": {
            "qwen-turbo": "Certainly! The issue you're encountering with the `doc = parser.parseInput(docData, baseUri);` line is that it's being called twice when the charset is detected and needs to be re-decoded. To fix this, we should ensure that we only call `parser.parseInput` once after we have the correct `docData`.\n\nHere is the corrected method:\n\n```java\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(\"UTF-8\").decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(\"UTF-8\")) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = parser.parseInput(docData, baseUri); // Parse again with the correct charset\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}\n```\n\nIn this corrected version, the `doc` is parsed again with the correct charset (`foundCharset`) inside the conditional block where the charset is determined from the `<meta>` tag. This ensures that `parser.parseInput` is only called once with the correct data.",
            "deepseek-chat": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = parser.parseInput(docData, baseUri); // Re-parse with the correct charset\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}",
            "gpt-4o-mini": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null;\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    \n    // Fix for the issue\n    // Re-parse document again if charset was updated after the first parse attempt (in the above logic)\n    if (doc == null && charsetName != null && !charsetName.equals(defaultCharset)) {\n        byteData.rewind();\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n    }\n\n    return doc;\n}",
            "doubao-pro-4k": "\u4ee5\u4e0b\u662f\u4fee\u6b63\u540e\u7684\u5b8c\u6574\u65b9\u6cd5\uff1a\n\n```java\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta!= null) { // if not found, will keep UTF-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\")? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset!= null && foundCharset.length()!= 0 &&!foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null;\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n        doc = parser.parseInput(docData.replaceAll(\"^\\uFEFF\", \"\"), baseUri);\n        doc.outputSettings().charset(charsetName);\n    }\n    return doc;\n}\n```",
            "ernie-3.5-128k": "Here is the complete corrected method with the fix for the potential issue in parsing the document:\n\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        // Parse the document with the initial assumption of defaultCharset\n        Document tempDoc = parser.parseInput(docData, baseUri);\n        Element meta = tempDoc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n            } else {\n                // If no valid charset found in meta, use the defaultCharset parsed document\n                doc = tempDoc;\n            }\n        } else {\n            // If no meta tag found, use the defaultCharset parsed document\n            doc = tempDoc;\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n    }\n\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n        // This block should not be reached as we have already parsed the document in one of the above conditions\n        // But just in case, let's keep the parsing logic here\n        doc = parser.parseInput(docData, baseUri);\n        doc.outputSettings().charset(charsetName);\n    } else {\n        // Ensure the output settings charset is set correctly even if the document was parsed earlier\n        doc.outputSettings().charset(charsetName != null ? charsetName : defaultCharset);\n    }\n\n    return doc;\n}\n\nIn this corrected method:\n1. I added a temporary document `tempDoc` to hold the parsed document when the charset is not specified and needs to be detected from the meta tags.\n2. I checked if a valid charset was found in the meta tags. If not, I used the `tempDoc` that was parsed with the default charset.\n3. I ensured that the `outputSettings().charset()` is set correctly for the final `doc` object, whether it was parsed initially or after re-decoding with the detected charset."
        },
        "prompt_apr_3": {
            "qwen-turbo": "```java\nstatic Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n    String docData;\n    Document doc = null;\n    if (charsetName == null) { // determine from meta. safe parse as UTF-8\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        docData = Charset.forName(defaultCharset).decode(byteData).toString();\n        doc = parser.parseInput(docData, baseUri);\n        Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n        if (meta != null) { // if not found, will keep utf-8 as best attempt\n            String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                charsetName = foundCharset;\n                byteData.rewind();\n                docData = Charset.forName(foundCharset).decode(byteData).toString();\n                doc = null;\n            }\n        }\n    } else { // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        docData = Charset.forName(charsetName).decode(byteData).toString();\n    }\n    if (doc == null) {\n        // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n        // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n        // into head mode\n        doc = parser.parseInput(docData, baseUri);\n```",
            "gpt-4o-mini": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        if (charsetName == null) { // determine from meta. safe parse as UTF-8\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            doc = parser.parseInput(docData, baseUri);\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            if (meta != null) { // if not found, will keep utf-8 as best attempt\n                String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                    charsetName = foundCharset;\n                    byteData.rewind();\n                    docData = Charset.forName(foundCharset).decode(byteData).toString();\n                    doc = null;\n                }\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n        }\n        if (doc == null) {\n            // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n            // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n            // into head mode\n\n            doc = parser.parseInput(docData.trim(), baseUri);",
            "deepseek-chat": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        if (charsetName == null) { // determine from meta. safe parse as UTF-8\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            doc = parser.parseInput(docData, baseUri);\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            if (meta != null) { // if not found, will keep utf-8 as best attempt\n                String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                    charsetName = foundCharset;\n                    byteData.rewind();\n                    docData = Charset.forName(foundCharset).decode(byteData).toString();\n                    doc = null;\n                }\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n        }\n        if (doc == null) {\n            // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n            // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n            // into head mode\n            if (docData.length() > 0 && docData.charAt(0) == '\\uFEFF') {\n                docData = docData.substring(1);\n            }\n            doc = parser.parseInput(docData, baseUri);\n        }",
            "doubao-pro-4k": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        if (charsetName == null) { // determine from meta. safe parse as UTF-8\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            doc = parser.parseInput(docData, baseUri);\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            if (meta!= null) { // if not found, will keep utf-8 as best attempt\n                String foundCharset = meta.hasAttr(\"http-equiv\")? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n                if (foundCharset!= null && foundCharset.length()!= 0 &&!foundCharset.equals(defaultCharset)) { // need to re-decode\n                    charsetName = foundCharset;\n                    byteData.rewind();\n                    docData = Charset.forName(foundCharset).decode(byteData).toString();\n                    doc = null;\n                }\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n        }\n        if (doc == null) {\n            doc = parser.parseInput(Strings.strip(docData), baseUri);\n        }\n}",
            "ernie-3.5-128k": "static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {\n        String docData;\n        Document doc = null;\n        if (charsetName == null) { // determine from meta. safe parse as UTF-8\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            docData = Charset.forName(defaultCharset).decode(byteData).toString();\n            doc = parser.parseInput(docData, baseUri);\n            Element meta = doc.select(\"meta[http-equiv=content-type], meta[charset]\").first();\n            if (meta != null) { // if not found, will keep utf-8 as best attempt\n                String foundCharset = meta.hasAttr(\"http-equiv\") ? getCharsetFromContentType(meta.attr(\"content\")) : meta.attr(\"charset\");\n                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode\n                    charsetName = foundCharset;\n                    byteData.rewind();\n                    docData = Charset.forName(foundCharset).decode(byteData).toString();\n                    doc = null;\n                }\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n            docData = Charset.forName(charsetName).decode(byteData).toString();\n        }\n        if (doc == null) {\n            // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present\n            // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight\n            // into head mode\n            docData = stripBOM(docData);\n            doc = parser.parseInput(docData, baseUri);\n        }"
        },
        "prompt_apr_4": {
            "qwen-turbo": "[\n    {\n        \"line_number\": 27,\n        \"fixed_statement\": \"if (foundCharset != null && !foundCharset.isEmpty() && !foundCharset.equalsIgnoreCase(defaultCharset)) {\"\n    }\n]",
            "doubao-pro-4k": "[\n    {\n        \"line_number\": 27,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri); doc.outputSettings().charset(charsetName);\"\n    }\n]",
            "ernie-3.5-128k": "[\n    {\n        \"line_number\": 27,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\\n                if (doc != null) {\"\n    }\n]",
            "deepseek-chat": "[\n    {\n        \"line_number\": 27,\n        \"fixed_statement\": \"doc = parser.parseInput(docData.replace(\\\"\\\\uFEFF\\\", \\\"\\\"), baseUri);\"\n    }\n]",
            "gpt-4o-mini": "[\n    {\n        \"line_number\": 27,\n        \"fixed_statement\": \"docData = Charset.forName(foundCharset).decode(byteData).toString();\"\n    }\n]"
        },
        "prompt_apr_5": {
            "qwen-turbo": "[\n    {\n        \"line_number\": 16,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    },\n    {\n        \"line_number\": 29,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    }\n]",
            "doubao-pro-4k": "[\n    {\n        \"line_number\": 16,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    }\n]",
            "deepseek-chat": "[\n    {\n        \"line_number\": 5,\n        \"fixed_statement\": \"docData = Charset.forName(\\\"UTF-8\\\").decode(byteData).toString();\"\n    },\n    {\n        \"line_number\": 6,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    },\n    {\n        \"line_number\": 21,\n        \"fixed_statement\": \"doc = parser.parseInput(docData.replace(\\\"\\\\uFEFF\\\", \\\"\\\"), baseUri);\"\n    }\n]",
            "ernie-3.5-128k": "[\n    {\n        \"line_number\": 12,\n        \"fixed_statement\": \"doc = parser.parseInput(stripBOM(docData), baseUri);\"\n    },\n    {\n        \"line_number\": 24,\n        \"fixed_statement\": \"doc = parser.parseInput(stripBOM(docData), baseUri);\"\n    }\n]",
            "gpt-4o-mini": "[\n    {\n        \"line_number\": 38,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    },\n    {\n        \"line_number\": 47,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    }\n]"
        },
        "prompt_apr_6": {
            "qwen-turbo": "[\n    {\n        \"line_number\": 22,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    }\n]",
            "doubao-pro-4k": "[\n    {\n        \"line_number\": 22,\n        \"fixed_statement\": \"doc = parser.parseInput(docData.trim(), baseUri);\"\n    }\n]",
            "ernie-3.5-128k": "[\n    {\n        \"line_number\": 25,\n        \"fixed_statement\": \"doc = parser.parseInput(stripBOM(docData), baseUri);\"\n    }\n]",
            "deepseek-chat": "[\n    {\n        \"line_number\": 24,\n        \"fixed_statement\": \"            docData = docData.replace(\\\"\\\\uFEFF\\\", \\\"\\\"); // Remove BOM if present\"\n    },\n    {\n        \"line_number\": 25,\n        \"fixed_statement\": \"            doc = parser.parseInput(docData, baseUri);\"\n    }\n]",
            "gpt-4o-mini": "[\n    {\n        \"line_number\": 38,\n        \"fixed_statement\": \"doc = parser.parseInput(docData, baseUri);\"\n    }\n]"
        }
    }
]